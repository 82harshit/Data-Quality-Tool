from sqlalchemy import create_engine, Column, Integer, String, Float, Boolean, Date, JSON, ForeignKey
from sqlalchemy.orm import sessionmaker, Session, declarative_base, relationship
from datetime import datetime
import os
import json
from dotenv import load_dotenv
from retry import retry

from logging_config import dqt_logger
from job_state_singleton import JobStateSingleton
from database.db_models.job_run_status import JobRunStatusEnum

 
# Define Base class for models
Base = declarative_base()
 
# Define the Batch model
class Batch(Base):
    __tablename__ = 'batches'
 
    batch_id = Column(String(255), primary_key=True)
    job_id = Column(String(255), unique=True, nullable=False)  # Each batch has a unique job_id
    batch_date = Column(Date)
    data_quality_score = Column(Float)
 
# Define the Expectation model
class Expectation(Base):
    __tablename__ = 'expectations'
 
    expectation_id = Column(Integer, primary_key=True, autoincrement=True)
    batch_id = Column(String(255), ForeignKey('batches.batch_id'))
    expectation_type = Column(String(255))
    column = Column(String(255))
    success = Column(Boolean)
    exception_message = Column(String(255), nullable=True)
    exception_traceback = Column(String(255), nullable=True)
    result = Column(JSON)
    
    batch = relationship("Batch", back_populates="expectations")
    
# Define the reverse relationship on the Batch model
Batch.expectations = relationship("Expectation", back_populates="batch", cascade="all, delete-orphan")

class ValidationResult:
    def __init__(self):
        load_dotenv()
        DATABASE_URL = os.getenv('DATABASE_URL')
        self.engine = create_engine(DATABASE_URL)
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        self.job_state = JobStateSingleton
        self.retry_attempts = {}
        
    @retry(tries=3, delay=2, backoff=2, jitter=(1, 3), logger=dqt_logger)
    def upsert_batch(self, batch_id: str, job_id: str, batch_date, data_quality_score: float, db_session: Session) -> None:
        """
        Inserts or updates a batch record. If failed, retries 3 times.
        
        :param batch_id (str): The id of the batch that is to be inserted (generated by GE library)
        :job_id (str): The job_id associated with the batch being inserted
        :batch_date (datetime): The current date at which the batch is being inserted
        :data_quality_score (float): The score of the validation result (generated by GE library)
        :db_session (Session): The database session in which the data is to be inserted
        
        :return: None
        """
        function_name = "upsert_batch"
        self.retry_attempts[function_name] = self.retry_attempts.get(function_name, 0) + 1  # Increment retry count
        current_attempt = self.retry_attempts[function_name]
        max_attempts = 3  # Matches the `tries` parameter

        try:
            existing_batch = db_session.query(Batch).filter(Batch.batch_id == batch_id).first()
            if existing_batch:
                existing_batch.data_quality_score = data_quality_score
                info_msg = f"Updated batch {batch_id}"
                dqt_logger.info(info_msg)
                self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.INPROGRESS, status_message=info_msg)
            else:
                new_batch = Batch(batch_id=batch_id, job_id=job_id, batch_date=batch_date, data_quality_score=data_quality_score)
                db_session.add(new_batch)
                info_msg = f"Inserted new batch {batch_id}"
                dqt_logger.info(info_msg)
                self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.INPROGRESS, status_message=info_msg)
            db_session.commit()
        except Exception as e:
            db_session.rollback()
            # Access retry attempt number
            error_msg = f"Error in upserting batch on attempt {current_attempt}/{max_attempts}: {e}"
            dqt_logger.error(error_msg)
            self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.ERROR, status_message="Error in upserting batch.")
            raise Exception(error_msg)
        
    @retry(tries=3, delay=2, backoff=2, jitter=(1, 3), logger=dqt_logger)        
    def insert_expectation(self, expectation_data: dict, db_session: Session) -> None:
        """
        Inserts a new expectation record. If failed, retries 3 times.
        
        :param expecatation_date (dict): A dict containing the exepctations that is added in the current database session
        :db_seesion (Session): The database session in which the expecatation are inserted
        
        :return: None
        """
        function_name = "insert_expectation"
        self.retry_attempts[function_name] = self.retry_attempts.get(function_name, 0) + 1  # Increment retry count
        current_attempt = self.retry_attempts[function_name]
        max_attempts = 3  # Matches the `tries` parameter

        try:
            expectation = Expectation(**expectation_data)
            db_session.add(expectation)
            db_session.commit()
            dqt_logger.info(f"Inserted expectation: {expectation_data['expectation_type']}")
        except Exception as e:
            db_session.rollback()
            error_msg = f"Error in inserting batch on attempt {current_attempt}/{max_attempts}: {e}"
            dqt_logger.error(error_msg)
            self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.ERROR, status_message="Error in inserting expectation.")
            raise Exception(error_msg)
 
    def save_result_for_job_id(self, json_response: json, job_id: str) -> None:
        """
        Accepts the validation JSON response and job id. Executes upsert_batches and insert_expecatations
        to add validation results in table

        :param json_response (json): A JSON containing the validation results that needs to be inserted
        :param job_id (str): The job for which the validation results need to be inserted

        :return: None
        """
        db_session = self.SessionLocal()
        try:
            if 'results' not in json_response:
                error_msg = "Error: 'results' key not found in the response"
                dqt_logger.error(error_msg)
                self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.ERROR, status_message=error_msg)
                raise Exception(error_msg)
 
            results = json_response['results']
            if not results:
                error_msg = "Error: No results found in the response"
                dqt_logger.error(error_msg)
                self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.ERROR, status_message=error_msg)
                raise Exception(error_msg)
 
            batch_id = results[0]['expectation_config']['kwargs']['batch_id']
            batch_date = datetime.now().date()  # Assuming current date for simplicity
 
            statistics = json_response['statistics']
            success_percent = statistics.get('success_percent', 0.0)
            data_quality_score = success_percent
 
            # Insert batch record (upsert logic to avoid duplicates)
            self.upsert_batch(batch_id, job_id, batch_date, data_quality_score, db_session)
 
            for result in results:
                expectation_config = result['expectation_config']
                result_details = result['result']
                exception_info = result.get('exception_info', {})
 
                # Ensure 'expectation_type' exists before accessing it
                expectation_type = expectation_config.get('expectation_type')
                if not expectation_type:
                    error_msg = f"Error: 'expectation_type' not found for batch_id {batch_id}"
                    dqt_logger.error(error_msg)
                    self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.ERROR, status_message=error_msg)
                    continue  # Skip processing this result if the expectation_type is missing
 
                expectation = {
                    'batch_id': batch_id,
                    'expectation_type': expectation_type,
                    'column': expectation_config['kwargs'].get('column'),  
                    'success': result.get('success', False),
                    'exception_message': exception_info.get('exception_message', ''),
                    'exception_traceback': exception_info.get('exception_traceback', ''),
                    'result': result_details
                }
 
                info_msg = f"Inserting expectation:{expectation}"
                dqt_logger.info(info_msg)
                self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.INPROGRESS, status_message="Inserting expectation")
 
                self.insert_expectation(expectation, db_session)
 
            db_session.commit()
            dqt_logger.info("Data stored successfully.")
            self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.COMPLETED)
        except Exception as e:
            db_session.rollback()
            error_msg = f"Error processing data: {e}"
            dqt_logger.error(error_msg)
            self.job_state.update_state_of_job_id(job_status=JobRunStatusEnum.ERROR, status_message="Error processing data.")
        finally:
            db_session.close()
            